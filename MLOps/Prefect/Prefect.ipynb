{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefect 2 is a powerful **workflow orchestration** library for managing and automating data pipelines. It allows you to define, run, and monitor data workflows with ease, while handling common challenges like retries, scheduling, and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "source": [
    "Prefect uses the concept of \"flows\" and \"tasks.\"\n",
    "\n",
    "- **Task**: An individual operation or step in a pipeline.\n",
    "- **Flow**: A collection of tasks that define the overall pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "source": [
    "Tasks are defined using the **@task** decorator. A task can be a function that performs a data transformation or other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task\n",
    "\n",
    "@task(log_prints=True)\n",
    "def fetch_data(api_url: str):\n",
    "    \"\"\"\n",
    "    Fetch data from the specified API URL.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    print(f\"Fetching data from {api_url}...\")\n",
    "    response = requests.get(api_url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Flow class** holds the tasks. You can define dependencies between tasks by chaining them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow\n",
    "\n",
    "@flow\n",
    "def etl_pipeline(api_url: str):\n",
    "    \"\"\"\n",
    "    ETL pipeline flow: orchestrates extract, transform, and load tasks.\n",
    "    \"\"\"\n",
    "    raw_data = fetch_data(api_url)\n",
    "    processed_data = transform_data(raw_data)\n",
    "    load_data(processed_data)\n",
    "\n",
    "etl_pipeline(api_url=\"https://api.example.com/sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and Loading Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefect supports the storage of flows so that you can easily load and run them later. You can store flows on various platforms like **GitHub, S3, and Prefect Cloud**m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Flows Locally\n",
    "To store a flow locally, use the **Local storage class**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.storage import Local\n",
    "\n",
    "# Define local storage and assign it to the flow\n",
    "flow.storage = Local(directory=\"flows/\")  # Save the flow to the \"flows/\" directory\n",
    "\n",
    "# Save the flow\n",
    "flow.save(\"my_local_flow.prefect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Flows\n",
    "Once your flow is stored, you can load it from storage. If you're using Prefect Cloud, itâ€™s automatically registered.\n",
    "\n",
    "- To load from a local file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import Flow\n",
    "\n",
    "# Load the flow\n",
    "loaded_flow = Flow.load(\"flows/my_local_flow.prefect\")\n",
    "\n",
    "# Run the loaded flow\n",
    "state = loaded_flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling and Monitoring Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefect provides easy **scheduling options** to **automate flow runs**. You can define schedules using the **CronSchedule** or **IntervalSchedule** classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling with Cron\n",
    "To run a flow periodically with a cron schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.schedules import CronSchedule\n",
    "\n",
    "@flow\n",
    "def daily_flow():\n",
    "    print(\"Running daily at 9 AM!\")\n",
    "\n",
    "schedule = CronSchedule(cron=\"0 9 * * *\")\n",
    "daily_flow.with_options(schedule=schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "- **CronSchedule(\"0 0 \\* \\* \\*\")** schedules the flow to run at midnight every day.\n",
    "- The **schedule** parameter is passed to the flow to automate the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling with Interval\n",
    "For intervals, use the IntervalSchedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.schedules import IntervalSchedule\n",
    "from datetime import timedelta\n",
    "\n",
    "@flow\n",
    "def scheduled_flow():\n",
    "    print(\"Running every 5 minutes!\")\n",
    "\n",
    "schedule = IntervalSchedule(interval=timedelta(minutes=5))\n",
    "scheduled_flow.with_options(schedule=schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "- **@task(max_retries=3, retry_delay=timedelta(seconds=10))** specifies that the task will be retried up to 3 times with a 10-second delay between retries if it fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Failures and Retries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefect allows **retry logic for tasks**. You can define retries with a maximum number of attempts and a delay between retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(retries=3, retry_delay_seconds=10)\n",
    "def unreliable_task():\n",
    "    import random\n",
    "    if random.random() < 0.7:\n",
    "        raise ValueError(\"Simulated failure!\")\n",
    "    print(\"Task succeeded!\")\n",
    "\n",
    "@flow\n",
    "def retry_example():\n",
    "    unreliable_task()\n",
    "\n",
    "retry_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **retries**: Number of retry attempts.\n",
    "- **retry_delay_seconds**: Time between retries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefect Executors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefect supports multiple execution environments through executors. The most common ones are the **LocalExecutor** and **DaskExecutor** for parallel execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocalExecutor (Default)\n",
    "By default, Prefect runs tasks sequentially using the LocalExecutor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DaskExecutor for Parallelism\n",
    "To use Dask for parallel execution, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install prefect[extras] dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the **DaskExecuter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.executors import DaskExecutor\n",
    "from prefect import Flow\n",
    "\n",
    "with Flow(\"Parallel ETL\", executor=DaskExecutor()) as flow:\n",
    "    data1 = extract_data()\n",
    "    data2 = extract_data()\n",
    "    transformed_data1 = transform_data(data1)\n",
    "    transformed_data2 = transform_data(data2)\n",
    "    load_data(transformed_data1)\n",
    "    load_data(transformed_data2)\n",
    "\n",
    "flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For production, Prefect supports deployment options to cloud services like Kubernetes, Docker, and AWS Batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.storage import Docker\n",
    "\n",
    "flow.storage = Docker(registry_url=\"your-docker-repo\", image_name=\"prefect-pipeline\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
